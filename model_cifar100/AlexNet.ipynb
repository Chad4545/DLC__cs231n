{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AlexNet.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpOXTJnIVMGC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import sampler\n",
        "\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as T\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import timeit\n",
        "# data\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Vj1Xxnxdo1e",
        "colab_type": "text"
      },
      "source": [
        "## 데이터 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_6pUin321Cr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar100.load_data()\n",
        "\n",
        "cifar100_train = [(torch.Tensor(x), y) for x,y in zip(x_train.transpose(0,3,1,2), y_train.flatten())]\n",
        "cifar100_test = [(torch.Tensor(x), y) for x,y in zip(x_test.transpose(0,3,1,2), y_test.flatten())]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXJkVxBGZRcI",
        "colab_type": "code",
        "outputId": "a712ab42-0600-4bd2-f0d0-8012448ed5dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((50000, 32, 32, 3), (50000, 1), (10000, 32, 32, 3), (10000, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2f8B6-mrduuJ",
        "colab_type": "text"
      },
      "source": [
        "## Dataloader 생성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r05C5CWtY1RC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def reset(m):\n",
        "    if hasattr(m, 'reset_parameters'):\n",
        "        m.reset_parameters()\n",
        "\n",
        "class ChunkSampler(sampler.Sampler):\n",
        "    \"\"\"Samples elements sequentially from some offset. \n",
        "    Arguments:\n",
        "        num_samples: # of desired datapoints\n",
        "        start: offset where we should start selecting from\n",
        "    \"\"\"\n",
        "    def __init__(self, num_samples, start = 0):\n",
        "        self.num_samples = num_samples\n",
        "        self.start = start\n",
        "\n",
        "    def __iter__(self):\n",
        "        return iter(range(self.start, self.start + self.num_samples))\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_samples\n",
        "    \n",
        "NUM_TRAIN = 49000\n",
        "NUM_VAL = 1000\n",
        "\n",
        "loader_train = DataLoader(cifar100_train, batch_size=64, sampler=ChunkSampler(NUM_TRAIN, 0))\n",
        "loader_val = DataLoader(cifar100_train, batch_size=64, sampler=ChunkSampler(NUM_VAL, NUM_TRAIN))\n",
        "loader_test = DataLoader(cifar100_test, batch_size=64)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "076nxlfgdxvQ",
        "colab_type": "text"
      },
      "source": [
        "## CUDA 여부 확인 False 일 경우 설정 변경"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgFNZooTd92e",
        "colab_type": "code",
        "outputId": "6c6d7f8f-d03f-40d8-bdb5-73f5f0e68136",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "torch.cuda.is_available()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzXpJZGH6cCq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dtype = torch.cuda.FloatTensor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CyxzHa8Td1vf",
        "colab_type": "text"
      },
      "source": [
        "## Train 및 Acc 함수 들 필요시 수정 가능 !"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1KeTtS1ZcgZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, loss_fn, optimizer, num_epochs, dtype):\n",
        "    for epoch in range(num_epochs):\n",
        "#         print('Starting epoch %d / %d' % (epoch + 1, num_epochs))\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for t, (x, y) in enumerate(loader_train):\n",
        "            x_var = Variable(x.type(dtype))\n",
        "            y_var = Variable(y.type(dtype).long())\n",
        "\n",
        "            scores = model(x_var)\n",
        "            \n",
        "            loss = loss_fn(scores, y_var)\n",
        "            total_loss += loss.data\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        if (epoch+1) % 10 == 0:\n",
        "            print(epoch+1)\n",
        "            print('loss = %.4f' % (total_loss/(t+1)))\n",
        "            print('train :')\n",
        "            check_accuracy(model, loader_val, dtype)\n",
        "\n",
        "def check_accuracy(model, loader, dtype):\n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    model.eval() # Put the model in test mode (the opposite of model.train(), essentially)\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x_var = Variable(x.type(dtype))\n",
        "\n",
        "            scores = model(x_var)\n",
        "            _, preds = scores.data.cpu().max(1)\n",
        "            num_correct += (preds == y).sum()\n",
        "            num_samples += preds.size(0)\n",
        "    acc = float(num_correct) / num_samples\n",
        "    print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xj-WLdb-d89B",
        "colab_type": "text"
      },
      "source": [
        "## 나만의 모델 생성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Nw737RTe0Jn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AlexNet(nn.Module):\n",
        "    def __init__(self, num_classes, dtype):\n",
        "        super(AlexNet, self).__init__()\n",
        "        self.dtype = dtype\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=5),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        ).type(dtype)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(256, 512),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.Linear(512, num_classes)\n",
        "        ).type(dtype)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYlRKiCRe0BG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "alexnet = AlexNet(100, dtype)\n",
        "loss_fn = nn.CrossEntropyLoss().type(dtype)\n",
        "optimizer = optim.Adam(alexnet.parameters(),lr=1e-4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IM0jgPs-d_cu",
        "colab_type": "text"
      },
      "source": [
        "## Train and check"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDZ8VKPr0C-J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "c7317161-13f1-4cc8-e435-8e119fac9fd9"
      },
      "source": [
        "alexnet"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AlexNet(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(5, 5))\n",
              "    (1): ReLU(inplace)\n",
              "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "    (4): ReLU(inplace)\n",
              "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (7): ReLU(inplace)\n",
              "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (9): ReLU(inplace)\n",
              "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace)\n",
              "    (12): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=256, out_features=512, bias=True)\n",
              "    (1): Linear(in_features=512, out_features=512, bias=True)\n",
              "    (2): Linear(in_features=512, out_features=100, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hi99DAqyZhUJ",
        "colab_type": "code",
        "outputId": "c6ae1229-3bff-4c47-a675-075eb2834491",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        }
      },
      "source": [
        "torch.cuda.random.manual_seed(12345)\n",
        "alexnet.apply(reset)\n",
        "train(alexnet, loss_fn, optimizer, 100, dtype)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10\n",
            "loss = 1.8545\n",
            "train :\n",
            "Got 275 / 1000 correct (27.50)\n",
            "20\n",
            "loss = 0.4440\n",
            "train :\n",
            "Got 275 / 1000 correct (27.50)\n",
            "30\n",
            "loss = 0.2101\n",
            "train :\n",
            "Got 281 / 1000 correct (28.10)\n",
            "40\n",
            "loss = 0.1686\n",
            "train :\n",
            "Got 282 / 1000 correct (28.20)\n",
            "50\n",
            "loss = 0.1275\n",
            "train :\n",
            "Got 291 / 1000 correct (29.10)\n",
            "60\n",
            "loss = 0.1080\n",
            "train :\n",
            "Got 276 / 1000 correct (27.60)\n",
            "70\n",
            "loss = 0.1048\n",
            "train :\n",
            "Got 279 / 1000 correct (27.90)\n",
            "80\n",
            "loss = 0.1042\n",
            "train :\n",
            "Got 288 / 1000 correct (28.80)\n",
            "90\n",
            "loss = 0.0961\n",
            "train :\n",
            "Got 278 / 1000 correct (27.80)\n",
            "100\n",
            "loss = 0.0985\n",
            "train :\n",
            "Got 292 / 1000 correct (29.20)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jztEsG47g7xh",
        "colab_type": "code",
        "outputId": "f18aa455-e294-4e5f-b424-c721f4634b1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "check_accuracy(alexnet, loader_test, dtype)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Got 2897 / 10000 correct (28.97)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}